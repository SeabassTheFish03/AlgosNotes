This is likely the most challenging topic you will encounter in an Algorithms course, likely because you are not used to thinking in a dynamic way, and the definitions for Dynamic Programming (DP) specifically are very slippery. I've included a bunch of resources in the [[#Links]] section, acknowledging that I likely won't be able to describe it perfectly. A good understanding of Dynamic Programming will serve you well through the rest of the course.
# Definitions
## Disclaimer
One of the reasons the understanding of DP is so slippery is because a few other concepts have to be explained first, before the actual definition can even be understood. I'm going to break the mold a little bit by giving you the final, unabridged definition first, using concepts you likely haven't seen yet. Then, I'll work my way through the unfamiliar concepts. My thought is that, by knowing where we end, you can better understand what motivates each concept.
## Dynamic Programming
Dynamic Programming is an algorithmic [[Design Techniques|design technique]] that aims to break a problem down into subproblems that can be solved recursively or iteratively. In contrast to something like [[Divide-and-Conquer]], where the subproblems do not overlap, dynamic programming specifically refers to problems where the subproblems *do* overlap, and their solutions can be [[#Memoization|memoized]] or cached, with the goal of only solving each subproblem once.
# Links
[[Design Techniques|Unit Home]]
[[CS385 - Algorithms|Course Home]]

Core concepts pulled from [Dr. O's Medium Article](https://medium.com/@cokasaki/exploring-dynamic-programming-part-1-32e3b329ca90) and the [Course Website](https://eecscourses.westpoint.edu/courses/cs385/index.html)
[YouTube Videos](https://www.youtube.com/results?search_query=dynamic+programming) on Dynamic Programming, generally pretty high quality.
## Tags
#design_techniques 